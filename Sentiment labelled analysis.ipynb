{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9944ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99be4f",
   "metadata": {},
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a32905",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "name = ['imdb_labelled', 'amazon_cells_labelled','yelp_labelled']\n",
    "for i in name :\n",
    "    files = open(f'{i}.txt', \"r\")\n",
    "    \n",
    "    data = files.readlines()\n",
    "   \n",
    "    for d in data:\n",
    "        d = d.split(\"\\t\")\n",
    "        corpus.append(d[0])\n",
    "        labels.append(d[1].replace(\"\\n\", \"\"))\n",
    "        files.close()\n",
    "\n",
    "        #labels, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05f076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd22470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7765876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the corpus\n",
    "X = []\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "for user_text in corpus:\n",
    "    # Remove puntuations and numbers\n",
    "    user_text = re.sub('[^a-zA-Z]', ' ', user_text)\n",
    "    # Remove single characters\n",
    "    user_text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', user_text)\n",
    "\n",
    "    # remove multiple spaces\n",
    "    user_text = re.sub(r'\\s+', ' ', user_text)\n",
    "    user_text = user_text.lower()\n",
    "    # spliting text\n",
    "    # Remove unncecessay stopwords\n",
    "    user_text = [word for word in user_text.split() if not word in stopwords.words(\"english\")]\n",
    "    \n",
    "    newString=''\n",
    "    for i in user_text:                                                 \n",
    "        newString=newString + stemmer.stem(i)+' '    #converting words to lemma\n",
    "        \n",
    "    \n",
    "    X.append(newString.strip())\n",
    "#create dataFrame\n",
    "df_data = pd.DataFrame(columns=['Phrase','label'])      \n",
    "for data, label in zip(X, labels):\n",
    "    df_data.loc[len(df_data.index)] = [data,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a51a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slow move aimless movi distress drift young man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sure lost flat charact audienc near half walk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempt arti black white clever camera angl mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>littl music anyth speak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best scene movi gerardo tri find song keep run...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>think food flavor textur lack</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>appetit instant gone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>overal impress would go back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>whole experi underwhelm think go ninja sushi n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>wast enough life pour salt wound draw time too...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Phrase label\n",
       "0       slow move aimless movi distress drift young man     0\n",
       "1         sure lost flat charact audienc near half walk     0\n",
       "2     attempt arti black white clever camera angl mo...     0\n",
       "3                               littl music anyth speak     0\n",
       "4     best scene movi gerardo tri find song keep run...     1\n",
       "...                                                 ...   ...\n",
       "2995                      think food flavor textur lack     0\n",
       "2996                               appetit instant gone     0\n",
       "2997                       overal impress would go back     0\n",
       "2998  whole experi underwhelm think go ninja sushi n...     0\n",
       "2999  wast enough life pour salt wound draw time too...     0\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935857f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE COUNT FEATURES AS VECTORS\n",
    "def count_vectorize(X_train, X_test):\n",
    "                count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "                count_vect.fit(X_train)\n",
    "\n",
    "                # transform the training and validation data using count vectorizer object\n",
    "                xtrain_count = count_vect.transform(X_train)\n",
    "                xvalid_count = count_vect.transform(X_test)\n",
    "\n",
    "                return xtrain_count,xvalid_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65bc168b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def word_TF_IDF_vectorize( X_train, X_test):\n",
    "                tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "                tfidf_vect.fit(X_train)\n",
    "\n",
    "                xtrain_tfidf = tfidf_vect.transform(X_train)\n",
    "                xvalid_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "                return xtrain_tfidf, xvalid_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d92e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into training(80%) and testing data(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data['Phrase'], df_data['label'], test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90e44cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_count, xvalid_count = count_vectorize(X_train, X_test)\n",
    "xtrain_tfidf, xvalid_tfidf = word_TF_IDF_vectorize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0694d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_model(classifier, X_train, X_test, y_train, y_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return classifier, metrics.classification_report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1f782ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, Count Vectors:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       299\n",
      "           1       0.79      0.81      0.80       301\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.80      0.80      0.80       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "NB_cv, accuracy = train_ml_model(naive_bayes.MultinomialNB(), xtrain_count, xvalid_count, y_train, y_test)\n",
    "print(\"Naive Bayes, Count Vectors:\\n \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad18e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, WordLevel TF-IDF:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       296\n",
      "           1       0.79      0.80      0.80       304\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.80      0.79      0.79       600\n",
      "weighted avg       0.80      0.80      0.79       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "NB_word_tf_idf, accuracy = train_ml_model(naive_bayes.MultinomialNB(), xtrain_tfidf, xvalid_tfidf, y_train, y_test)\n",
    "print(\"Naive Bayes, WordLevel TF-IDF:\\n \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1d38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
